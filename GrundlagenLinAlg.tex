\chapter{Grundlagen aus der linearen Algebra}
\section{Norm und Kondition}
Zwei Matrixnormen werden im Laufe der Arbeit von entscheidener Bedeutung sein, weshalb wir uns zunächst an deren Definition erinnern.

\begin{mydef}[Frobenius- und Zeilensummennorm]
    Sei $A = (a_{kj})_{k,j=0}^{n-1} \in \C^{n\times n}$ eine Matrix.
    Die \emph{Frobeniusnorm} von $A$ ist definiert durch
    \begin{equation}
        \label{eq:frobenius_norm}
        \norm{A}_F
        \defeq \sqrt{ \sum_{k=0}^{n-1} \sum_{j=0}^{n-1} \abs{a_{kj}}^2}.
    \end{equation}

    \noindent Die \emph{Zeilensummennorm} von $A$ ist definiert durch
    \begin{equation}
        \label{eq:infinity_norm}
        \norm{A}_\infty
        \defeq \max_{k=0, \dots, n-1} \sum_{j=0}^{n-1} \abs{a_{kj}}.
    \end{equation}
\end{mydef}

Wir betrachten ein lineares Gleichungssystem der Form
$Ax = b$ mit invertierbarer Matrix
$A \in \C^{n \times n}$, $n \in \N$, $b \in \Cn$
und gesuchten Vektor $x \in \Cn$.
Dabei nehmen wir $x \neq 0$ und $b \neq 0$ an.
Weiter sei nur ein verfälschter Eingangsvektor $\tilde{b} = b + \Delta b$
mit relativem Fehler
\[
    \frac{\norm{\tilde{b} - b}}{\norm{b}} = \frac{\norm{\Delta b}}{\norm{b}} \leq \delta
\]
gegeben.
Wir bezeichnen mit $\tilde{x}$ die Lösung des verfälschten Gleichungssystems
$A \tilde{x} = \tilde{b}$.
Wegen der Linearität von $A^{-1}$ erhalten wir
\[
    \tilde{x} = A^{-1} \tilde{b} = A^{-1} b + A^{-1} \Delta b = x + \Delta x,
\]
wobei $\Delta x \defeq A^{-1} \Delta b$.

\noindent Gesucht ist nun ein Maß des relativen Fehlers der verfälschten Lösung
$\tilde{x}$ in Abhängigkeit vom Eingangsfehler $\delta$.
Wegen $ \norm{\Delta x} = \norm{A^{-1} \Delta b} \leq \norm{A^{-1}} \norm{\Delta b} $
und $ \norm{b} = \norm{A x} \leq \norm{A} \norm{x} $,
folgt für den relativen Fehler:
\[
    \frac{\norm{\Delta x}}{\norm{x}} \leq \norm{A} \norm{A^{-1}} \frac{\norm{\Delta b}}{\norm{b}} \leq \norm{A} \norm{A^{-1}} \delta.
\]

\noindent Dies motiviert die folgende
\begin{mydef}[Kondition einer Matrix]
    Sei $A \in \C^{n \times n}$.
    Die \emph{Kondition von $A$} ist durch
    $\cond{A} \defeq \norm{A} \norm{A^{-1}}$
    definiert.
\end{mydef}

\begin{remark}
    Mit der vorherigen Definition gilt nun: $ \frac{\norm{\Delta x}}{\norm{x}} \leq \cond{A} \cdot \delta $.
\end{remark}

\section{Vandermonde-Matrizen}

\begin{mydef}[Vandermonde-Matrix]
    Für $n \in \N$ und einen Vektor ${z = (z_0, \dots, z_{n-1}) \in \Cn}$
    sei die
    \emph{Vandermonde-Matrix zu den Stützstellen (oder Knoten) $z_0, \dots, z_{n-1}$}
    durch
    \[
        \Vand{z} \defeq \begin{pmatrix}
            1         & 1         & \dots & 1 \\
            z_0       & z_1       & \dots & z_{n-1} \\
            z_0^2     & z_1^2     & \dots & z_{n-1}^2 \\
            \vdots    & \vdots    & \dots & \vdots \\
            z_0^{n-1} & z_1^{n-1} & \dots & z_{n-1}^{n-1}
        \end{pmatrix}
    \]
    definiert.
    Bezeichnet man die Komponenten der Vandermonde-Matrix mit
    $\left( v_{kj} \right)_{k,j = 0}^{n-1}$, so ergibt sich:
    $ v_{kj} = z_j^k $ für $k, j = 0, \dots, n-1$.

\end{mydef}

\begin{lemma}
    Sei $z = (z_0, \dots, z_{n-1}) \in \Cn$.
    Es gilt
    \[
        \det \Vand{z} = \prod_{0 \leq k < j \leq n-1} \left( z_j - z_k \right).
    \]
\end{lemma}

\begin{proof}
    Bezeichne mit $v_{kj} = z_j^k$ für $k,j \in \{0, \dots, n-1\}$ die Elemente von $\Vand{z}$.
    Der Beweis erfolgt durch vollständige Induktion über $n \in \N$.\\
    \textbf{Induktionsanfang (\boldmath $n=1$):}\\
    Da das leere Produkt $1$ ergibt, gilt
    $\det{\Vand{z}}~=~1~=~\prod_{0 \leq k < j \leq 0} (z_j~-~z_k)$. \\[0.5em]
    \textbf{Induktionvoraussetzung:}
    Sei die Behauptung für $n-1 \in \N$ erfüllt.\\[0.5em]
    \textbf{Induktionsschritt (\boldmath $n\!-\!1 \rightarrow n$):}
    Durch Zeilenoperationen ändert sich der Wert der Determinante nicht.
    Wir ziehen daher in jeder Zeile das $z_0$-fache der vorherigen Zeile ab.
    \[
        \det{\Vand{z}}
        = \begin{vmatrix}
            1         & 1         & \dots & 1 \\
            z_0       & z_1       & \dots & z_{n-1} \\
            z_0^2     & z_1^2     & \dots & z_{n-1}^2 \\
            \vdots    & \vdots    & \dots & \vdots \\
            z_0^{n-1} & z_1^{n-1} & \dots & z_{n-1}^{n-1}
        \end{vmatrix}
        = \begin{vmatrix}
            1      & 1                  & \dots & 1 \\
            0      & (z_1-z_0)          & \dots & (z_{n-1}-z_0) \\
            0      & (z_1-z_0)z_1^1     & \dots & (z_{n-1}-z_0) z_{n-1}^1 \\
            \vdots & \vdots             & \dots & \vdots \\
            0      & (z_1-z_0)z_1^{n-2} & \dots & (z_{n-1}-z_0) z_{n-1}^{n-2}
        \end{vmatrix}.
    \]
    Entwicklung der Determinante nach der ersten Spalte mit Hilfe des
    Laplaceschen Entwicklungssatzes und Ausnutzung der Multilinearität der
    Determinante, liefert nun die Behauptung:
    \[
        \begin{split}
            \det{\Vand{z}}
            &= \prod_{j=0}^{n-1} (z_j - z_0) \begin{vmatrix}
                1         & \dots & 1 \\
                z_1       & \dots & z_{n-1} \\
                z_1^2     & \dots & z_{n-1}^2 \\
                \vdots    & \dots & \vdots \\
                z_1^{n-2} & \dots & z_{n-1}^{n-2}
            \end{vmatrix}
            = \prod_{j=0}^{n-1} (z_j - z_0) \det{\Vand{z_1, \dots, z_{n-1}}}\\
            &\overset{IV}{=} \prod_{j=0}^{n-1} (z_j - z_0) \prod_{1 \leq k < r \leq n-1} (z_r - z_k)
            = \prod_{0 \leq k < r \leq n-1} (z_r - z_k).
        \end{split}
    \]
\end{proof}

\begin{corollary}
    Die Vandermonde-Matrix $\Vand{z}$ mit
    $z = (z_0, \dots, z_{n-1}) \in \Cn$ ist genau dann invertierbar, wenn
    $z_k \neq z_j$ für alle $k \neq j$, d.h. wenn die $z_k$ paarweise
    verschieden sind.
\end{corollary}
