\chapter{Eine Ungleichung für die Kondition von Vandermonde-Matrizen}
In diesem Abschnitt sei ein $n$-elementiger Vektor $z = (z_0, \dots, z_{n-1})
\in \Cn$ gegeben.  Die zugehörige Vandermonde-Matrix sei mit $V \defeq
\Vand{z}$ bezeichnet.  Ziel ist es, eine Abschätzung der Zeilensummennorm
inverser Vandermonde-Matrizen und damit eine Abschätzung der
Kondition $\cond[\infty]{V}$ zu finden.

% TODO: reference gautschi1

\section{Inversion der Vandermonde-Matrix}
Es werden zunächst die \emph{Lagrange-Polynome} zu den Knoten
$z_0, \dots, z_{n-1}$ eingeführt, deren Koeffizienten sich als Einträge der
inversen Vandermonde-Matrix herausstellen werden.

\begin{mydef}[Lagrange-Polynome]
    Für $ z = (z_0, \dots, z_{n-1}) \in \Cn $ definiere die
    \emph{Lagrange-Polynome} durch
    \[
        l_j(z)
        \defeq \prod_{\substack{r=0\\ r \neq j}}^{n-1} \frac{z - z_r}{z_j - z_r} \text{ für } j = 0, \dots, n-1.
    \]
\end{mydef}

\begin{remark}
    $ \; $
    \begin{enumerate}
        \item Es gilt $l_j \in \Pi_{n-1}$, wobei $\Pi_{n-1}$ den Raum der Polynome bis
        Grad $n-1$ bezeichne.
        \item  Einfaches Nachrechnen liefert
        $l_j(z_r) = \delta_{jr}$, wobei $\delta_{jr}$ das Kronecker-Delta
        sei.
    \end{enumerate}
\end{remark}

\noindent Wegen $l_j \in \Pi_{n-1}$ können die Lagrange-Polynome ausmultipliziert als
\begin{equation}
    \label{eq:lagrange}
    l_j(z) = \sum_{r = 0}^{n-1} u_{jr} z^{r}
\end{equation}
mit den Koeffizienten $u_{jr} \in \C$ geschrieben werden.

Im folgenden Lemma zeigt sich, dass die Koeffizienten der Lagrange-Polynome
genau den Einträgen der inversen Vandermonde-Matrix entsprechen.
\begin{lemma}[\cite{gautschi3}]
    \label{lemma:vandermonde-inversion}
    Sei $z = (z_0, \dots, z_{n-1}) \in \Cn$ und seien
    $l_j$ die zugehörigen Lagrange-Polynome für $j = 0, \dots, n-1$
    mit den Koeffizienten $u_{jr}$ wie in (\ref{eq:lagrange}).
    Dann ist die Koeffizienten-Matrix $U = (u_{jr})_{j,r = 0}^{n-1}$ die
    Inverse der Vandermonde-Matrix $V = \Vand{z} = (z_{j}^{k})_{k,j = 0}^{n-1}$.
\end{lemma}
\begin{proof}
    Wir betrachten das Gleichungssystem $V \alpha = y$ mit
    $\alpha = (\alpha_0, \dots, \alpha_{n-1}) \in \Cn$
    und $y = (y_0, \dots, y_{n-1}) \in \Cn$.
    Zum Beweis muss die Gleichung $U y = \alpha$ für alle $\alpha,  y \in \Cn$
    gezeigt werden.
    Es gilt für $j = 0, \dots, n-1$
    \[
        \begin{split}
            \sum_{k=0}^{n-1} u_{jk} y_k &= \sum_{k=0}^{n-1} u_{jk} \sum_{r=0}^{n-1} z_r^k \alpha_r = \sum_{r=0}^{n-1} \alpha_r \sum_{k=0}^{n-1} u_{jk} z_r^k\\
                                        &= \sum_{r=0}^{n-1} \alpha_r l_j(z_r) = \sum_{r=0}^{n-1} \alpha_r \delta_{jr} = \alpha_j,
        \end{split}
    \]
    wie behauptet.
\end{proof}

Unter Verwendung von Gleichung (\ref{eq:lagrange}) und den
elementarsymmetrischen Polynomen kann eine explizite Darstellung der
inversen Vandermonde-Matrix angegeben werden.
Dazu schreiben wir für $j = 0, \dots, n-1$
\begin{equation*}
    \sum_{r = 0}^{n-1} u_{jr} z^{r}
    = l_j(z)
    = \prod_{\substack{r=0\\ r \neq j}}^{n-1} \frac{z - z_r}{z_j - z_r}
    = \Pi_j \cdot \prod_{\substack{r=0\\ r \neq j}}^{n-1} \left( z - z_r \right)
\end{equation*}
mit
\begin{equation}
    \label{def:pi_j}
    \Pi_j \defeq \prod_{\substack{r=0\\ r \neq j}}^{n-1} \left( z_j - z_r \right)^{-1}.
\end{equation}

\noindent Nutzen wir Lemma
\ref{lemma:elementary_symmetric_polynomials_const_multiplication}, so erhalten
wir
\begin{lemma}
    Für $j, r = 0, \dots, n-1$ gilt
    \begin{equation}
        \label{eq:explicit_inverse_vandermonde}
        \begin{split}
            u_{jr}
            &= \Pi_j \sigma_{n-1-r}^{j}(-z_0, \dots, -z_{n-1})\\
            &\overset{(\ref{eq:elementary_symmetric_polynomials_const_multiplication})}{=}
                (-1)^{n-1-r} \Pi_j \sigma_{n-1-r}(z_0, \dots, z_{j-1}, z_{j+1}, \dots, z_{n-1}).
        \end{split}
    \end{equation}
\end{lemma}

\section{Eine Abschätzung der Zeilensummennorm inverser Vandermonde-Matrizen}

Zunächst sei ohne Beweis an Jensens Formel in Integralform erinnert, die wir im
folgenden Lemma benötigen werden.
\begin{theorem}
    \label{thm:jensens_formula}
    Sei $\rho \in \R_+$ und $F: \C \mapsto \C$ eine auf $\abs{x} \leq \rho$
    analytische Funktion mit $F(0) \neq 0$.
    Bezeichne mit $\zeta_1, \dots, \zeta_n \in \C$ die Nullstellen von $F$ mit
    $\abs{\zeta_j} \leq \rho$, wobei die Nullstellen entsprechend ihrer
    Vielfachheit eventuell mehrfach vorkommen.
    Jensens Formel in Integralform lautet dann
    \begin{equation}
        \frac{1}{2\pi} \int_{0}^{2 \pi} \log \abs{F\left( \rho e^{i\phi} \right)} d\phi
        = \log \abs{F(0)} + \sum_{j=1}^{n} \log \frac{\rho}{\abs{\zeta_j}}.
    \end{equation}
\end{theorem}

% TODO: a_0 /= 0 aus Jensen wird nicht beachtet.
\begin{lemma}[\cite{gautschi2}]
    \label{lemma:polynom_coefficient_sum_inequality}
    Sei $p(z) = \sum_{j = 0}^{n} a_j z^j$ ein Polynom $n$-ten Grades mit
    $a_j \in \C$ für $j = 0, \dots, n$, $a_n \neq 0$ und Nullstellen
    $\zeta_j \in \C$ mit $j = 1, \dots, n$.
    Dann gilt
    \begin{equation}
        \label{eq:polynom_coefficient_sum_inequality}
        \sum_{j=0}^{n} \abs{a_j} \geq \abs{a_n} \prod_{j=1}^{n} \max \left(1, \abs{\zeta_j} \right).
    \end{equation}
    Gleichheit gilt genau dann, wenn $p(z) = a_n z^n$.
\end{lemma}

% TODO: Beautify this proof.
\begin{proof}
    Ohne Einschränkung können wir annehmen, dass die Nullstellen sortiert
    vorliegen, so dass
    \[
        \zeta_1 \leq \dots \leq \zeta_r \leq 1 < \zeta_{r+1} \leq \dots \leq \zeta_n
    \]
    gilt.
    Wir identifizieren $p$ mit $F$ und wählen $\rho =1$ in Satz
    \ref{thm:jensens_formula}.
    Zusammen mit $\log \frac{1}{z} = -\log z$ liefert dieser dann
    \[
        \log \abs{a_0}
        = \log \abs{p(0)}
        = \sum_{k=1}^{r} \log \abs{\zeta_k} + \frac{1}{2\pi} \int_{0}^{2\pi} \log \abs{p\left( e^{i\varphi} \right)} d\varphi
    \]
    oder äquivalent dazu
    \begin{equation}
        \label{eq:jensen_polynom}
        \abs{a_0} \prod_{k=1}^{r} \abs{\zeta_k}^{-1}
        = \exp\left( \frac{1}{2\pi} \int_{0}^{2\pi} \log \abs{p\left( e^{i\varphi} \right)} d\varphi \right).
    \end{equation}

    \noindent Mit Hilfe der Nullstellen $\zeta_j$ können wir $p$ als Produkt
    seiner Linearfaktoren darstellen:
    \[
        p(z) = \sum_{j = 0}^{n} a_j z^j = a_n \prod_{k=1}^n (z-\zeta_k).
    \]

    \noindent Die Auswertung an $z=0$ liefert dann
    \[
        a_0 = p(0) = a_n (-1)^n \prod_{k=1}^n \zeta_k,
    \]
    so dass wir (\ref{eq:jensen_polynom}) vereinfacht darstellen können:
    \[
        \abs{a_n} \prod_{k=r+1}^{n} \abs{\zeta_k}
        = \exp\left( \frac{1}{2\pi} \int_{0}^{2\pi} \log \abs{p\left( e^{i\varphi} \right)} d\varphi \right).
    \]

    \noindent Mit
    \begin{equation}
        \label{eq:jensen_integral_estimation}
        \exp\left( \frac{1}{2\pi} \int_{0}^{2\pi} \log \abs{p\left( e^{i\varphi} \right)} d\varphi \right)
        \leq \max_{0 \leq \varphi \leq 2\pi} \abs{p\left( e^{i\varphi} \right) }
        = \max_{0 \leq \varphi \leq 2\pi} \abs{\sum_{j=0}^{n} a_j e^{i\varphi}}
        \leq \sum_{j=0}^{n} \abs{a_j}
    \end{equation}
    folgt nun wie behauptet
    \[
        \sum_{j=0}^n \abs{a_j} \geq \abs{a_n} \prod_{k=1}^n \max(1, \zeta_k).
    \]

    \noindent Für den Fall $p(z) = a_n x^n$, ist
    $ \sum_{j=0}^{n} \abs{a_j}
      = \abs{a_n} \cdot \prod_{r=1}^n \max(1, \abs{\zeta_r})
      = \abs{a_n} $
    trivialerweise erfüllt.
    Sei umgekehrt  ein beliebiges Polynom
    $p(z) = \sum_{j=0}^n a_j x^j$, $a_n \neq 0$ gegeben, das
    (\ref{eq:polynom_coefficient_sum_inequality}) mit
    Gleichheit erfüllt.
    Dies impliziert wegen (\ref{eq:jensen_integral_estimation}) insbesondere
    \[
        \exp\left( \frac{1}{2\pi} \int_{0}^{2\pi} \log \abs{p\left( e^{i\varphi} \right)} d\varphi \right)
        = \max_{0 \leq \varphi \leq 2\pi} \abs{p\left( e^{i\varphi} \right) }
        \eqdef M,
    \]
    und damit die Konstanz des Betrages $\abs{p(e^{i\varphi})} = M$ für
    $0 \leq \varphi \leq 2 \pi$.
    Wir betrachten das trigonometrische Polynom
    \[
        \abs{p\left( e^{i\varphi} \right)}^2
        = \sum_{k,j=0}^n a_k \conj{a}_j e^{i(k-j)\varphi}
        = \sum_{l=-n}^n c_l e^{i l \varphi}
    \]
    mit Koeffizienten\footnote{Hier sei $a_k = 0$ für $k<0$ und $k > n$.}
    \[
        c_l = \sum_{-\infty}^\infty a_k \conj{a}_{k-l} \text{ und } c_{-l} = \conj{c_l}.
    \]
    Wegen $\abs{p\left( e^{i\varphi} \right)}^2 \equiv M^2$ muss $c_j = 0$ für
    $j > 0$ und $c_0 = M^2$ gelten.
    Wir erhalten die Bedingungen
    \begin{equation*}
        \begin{split}
            0 &= c_n = a_n \conj{a}_0\\
            0 &= c_{n-1} = a_n \conj{a}_1 + a_{n-1} \conj{a}_0\\
              &\;\;\vdots\\
            0 &= c_1 = a_n \conj{a}_{n-1} + \dots + a_{1} \conj{a}_0\\
            M^2 &= c_0 = a_n^2 + \dots + a_0^2.
        \end{split}
    \end{equation*}
    Wegen $a_n \neq 0$ liefert die erste Bedingung $a_0 = 0$.
    Einsetzen von $a_0 = 0$ in die zweite Bedingung liefert aus dem gleichen
    Grund $a_1 = 0$ und induktiv folgen $a_j = 0$ für $j < n$.
    Schließlich zeigt die letzte Gleichung $M^2 = a_n^2$, so dass $p$ wie
    behauptet ein Polynom der Form $p(z) = a_n z^n$ ist.
\end{proof}

Nun können wir eine Abschätzung der Zeilensummennorm der inversen
Vandermonde-Matrix angeben und beweisen:
\begin{theorem}
  \label{thm:inverse_vandermonde_inequality}
  Seien $z_0, \dots, z_{n-1} \in \C$ paarweise verschieden.
  Mit $V \defeq \Vand{z}$ gilt
  \begin{equation}
    \label{eq:inverse_vandermonde_inequality}
    \max_{j = 0, \dots, n-1} \left( \prod_{\substack{k = 0\\ k \neq j}}^{n-1} \frac{\max(1, \abs{z_k})}{\abs{z_j - z_k}} \right)
    < \norm{V^{-1}}_{\infty}
    \leq \max_{j = 0, \dots, n-1} \left( \prod_{\substack{k = 0\\ k \neq j}}^{n-1} \frac{1 + \abs{z_k}}{\abs{z_j - z_k}} \right).
  \end{equation}
  Gleichheit für die obere Grenze gilt, wenn $z_k = r_k \cdot e^{i \varphi}$
  für ein festes $\varphi \in \R$ und $r_k \in \R_{+}$ mit $k = 0, \dots, n-1$ gilt.
\end{theorem}

\begin{proof}
    Der Beweis orientiert sich an der Beweisskizze aus
    \cite[S. 196-197]{gautschi1}.
    Die obere Schranke von (\ref{eq:inverse_vandermonde_inequality}) sieht man
    unter Verwendung der expliziten Darstellung von $V^{-1}$ aus
    (\ref{eq:explicit_inverse_vandermonde}) und der Ungleichung über
    elementarsymmetrische Polynome
    (\ref{eq:elementary_symmetric_polynomials_inequality}) aus Lemma
    \ref{lemma:elementary_symmetric_polynomials_inequality} ein.
    Es gilt
    \begin{equation*}
        \begin{split}
            \norm{V^{-1}}_{\infty}
            &= \max_{j=0, \dots, n-1} \sum_{r=0}^{n-1} \abs{u_{jr}}\\
            &\overset{(\ref{eq:explicit_inverse_vandermonde})}{=}
              \max_{j=0, \dots, n-1} \sum_{r=0}^{n-1} \abs{(-1)^{n-1-r} \Pi_j \sigma_{n-1-r}^{j}}
            = \max_{j=0, \dots, n-1} \abs{\Pi_j} \sum_{r=0}^{n-1} \abs{\sigma_{n-1-r}^{j}}\\
            &\overset{(\ref{eq:elementary_symmetric_polynomials_inequality})}{\leq}
              \max_{j=0, \dots, n-1} \abs{\Pi_j} \prod_{\substack{k=0\\ k \neq j}}^{n-1} \left( 1 + \abs{z_k} \right)
            \overset{(\ref{def:pi_j})}{=}
              \max_{j=0, \dots, n-1} \prod_{\substack{k=0\\ k \neq j}}^{n-1} \frac{1 + \abs{z_k}}{\abs{z_j - z_k}}.
        \end{split}
    \end{equation*}

    \noindent Für die untere Schranke wähle nun ein festes
    $j \in \{0, \dots, n-1\}$ und betrachte das Polynom
    \[
        p(z) = \sum_{k=0}^{n-1} a_k z^k
        \defeq \Pi_j \cdot \prod_{\substack{k=0\\ k \neq j}}^{n-1} \left( z - z_k \right)
        \overset{(\ref{eq:explicit_inverse_vandermonde})}{=} \sum_{k=0}^{n-1} (-1)^{n-1-k} \cdot \Pi_j \cdot \sigma_{n-1-k}^j(z_0, \dots, z_{n-1}) \cdot z^k,
    \]
    d.h. die Koeffizienten von $p$ ergeben sich für $k = 0, \dots, n-1$ durch
    \[
        a_k = (-1)^{n-1-k} \cdot \Pi_j \cdot \sigma_{n-1-k}^j(z_0, \dots, z_{n-1}).
    \]
    Offensichtlich hat $p$ die $n-1$ Nullstellen
    $\zeta_r \defeq z_r$ für $r \in \{0,\dots,n-1\} \setminus \{j\}$.
    Wegen $z_k \neq z_r$ für $k \neq r$ existieren für das Polynom $p$ Nullstellen ungleich $0$ und
    es kann nicht $p(z) \equiv a_{n-1} z^{n-1}$ gelten.
    Damit kann die strikte Ungleichung
    (\ref{eq:polynom_coefficient_sum_inequality}) aus Lemma
    \ref{lemma:polynom_coefficient_sum_inequality} angewendet werden und es
    folgt
    \[
        \begin{split}
            \sum_{r=0}^{n-1} \abs{u_{jr}}
            &\overset{(\ref{eq:explicit_inverse_vandermonde})}{=}
            \sum_{r=0}^{n-1} \abs{(-1)^{n-1-r} \Pi_j \sigma_{n-1-r}^j}\\
            &= \sum_{k=0}^{n-1} \abs{a_k}
            \overset{(\ref{eq:polynom_coefficient_sum_inequality})}{>}
                \abs{a_{n}} \prod_{\substack{r=0\\ r \neq j}}^{n-1} \max \left(1, \abs{\zeta_r} \right)\\
            &= \abs{\Pi_j} \underbrace{\abs{\sigma_0^j}}_{=1} \prod_{\substack{r=0\\ r \neq j}}^{n-1} \max \left(1, \abs{z_r} \right)
            = \prod_{\substack{r=0\\ r \neq j}}^{n-1} \frac{\max \left(1, \abs{z_r} \right)}{\abs{z_j - z_r}}.
        \end{split}
    \]

    \noindent Da diese Ungleichung für alle $j \in \{0, \dots, n-1\}$ erfüllt
    ist, folgt die Behauptung:
    \[
        \max_{j = 0, \dots, n-1} \sum_{r=0}^{n-1} \abs{u_{jr}}
        > \max_{j = 0, \dots, n-1} \prod_{\substack{r=0\\ r \neq j}}^{n-1} \frac{\max \left(1, \abs{z_r} \right)}{\abs{z_j - z_r}}.
    \]
\end{proof}

